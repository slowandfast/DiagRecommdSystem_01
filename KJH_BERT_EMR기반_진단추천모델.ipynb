{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "maG93-lmxLF-",
        "outputId": "b3044400-ab4d-4d3f-eabf-96e71aa4faf7",
        "scrolled": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.41.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.14.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.23.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.25.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2023.12.25)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n",
            "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.19.1)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.4)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.0->transformers) (2023.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.0->transformers) (4.11.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.2.2)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (0.18.0+cu121)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision) (1.25.2)\n",
            "Requirement already satisfied: torch==2.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision) (2.3.0+cu121)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision) (9.4.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch==2.3.0->torchvision) (3.14.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch==2.3.0->torchvision) (4.11.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch==2.3.0->torchvision) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch==2.3.0->torchvision) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch==2.3.0->torchvision) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch==2.3.0->torchvision) (2023.6.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch==2.3.0->torchvision) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch==2.3.0->torchvision) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch==2.3.0->torchvision) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch==2.3.0->torchvision) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch==2.3.0->torchvision) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch==2.3.0->torchvision) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch==2.3.0->torchvision) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch==2.3.0->torchvision) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch==2.3.0->torchvision) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /usr/local/lib/python3.10/dist-packages (from torch==2.3.0->torchvision) (2.20.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch==2.3.0->torchvision) (12.1.105)\n",
            "Requirement already satisfied: triton==2.3.0 in /usr/local/lib/python3.10/dist-packages (from torch==2.3.0->torchvision) (2.3.0)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch==2.3.0->torchvision) (12.5.40)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch==2.3.0->torchvision) (2.1.5)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch==2.3.0->torchvision) (1.3.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install torch>=1.7.1\n",
        "!pip install transformers\n",
        "!pip install torchvision"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SMZh3JGuBUcg"
      },
      "outputs": [],
      "source": [
        "# !pip install tensorflow\n",
        "# !pip install setuptools==69.5.1\n",
        "# !pip install --upgrade pip setuptools wheel\n",
        "# !pip install numpy --only-binary :all"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "rr4U2ShmBUch"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "# import gluonnlp as nlp\n",
        "from torch.utils.data import Dataset, DataLoader, TensorDataset\n",
        "from torch.optim import Adam\n",
        "from transformers import AutoTokenizer, AutoModel, AutoModelForSequenceClassification\n",
        "from transformers import BertTokenizer, BertModel\n",
        "from sklearn.model_selection import train_test_split\n",
        "# from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "import scipy.sparse as sp"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Sqpb8zGnBUch",
        "outputId": "c1802d50-c898-464e-ed3d-eb121d2e9b15"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'2.10.0'"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "tf.__version__"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "UeYrZyw2BUch",
        "outputId": "ebbea149-d2a9-4d9e-b5f5-05210c7cbb10",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda\n"
          ]
        }
      ],
      "source": [
        "device_name = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "device = torch.device(device_name)\n",
        "print(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 311
        },
        "id": "JGjdysN041BS",
        "outputId": "a1865326-8868-40cd-85f4-f5cbdda7f831"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "전체 데이터 수 : 826\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "  ICD10                            CC  \\\n",
              "0  N391                           NaN   \n",
              "1  N184  CKD4, Cr 2.26, eGFR 29ml/min   \n",
              "2  N184                          CKD4   \n",
              "3  N185           Cr 3.74, eGFR 13.56   \n",
              "4  N183               lab abnormality   \n",
              "\n",
              "                                                  PI  \\\n",
              "0  115-61-61_x000D_\\n2023.5.10._x000D_\\n_x000D_\\n...   \n",
              "1  130/61/69_x000D_\\n요증상(-), edema(-), 요독증상(-), D...   \n",
              "2  153/75/85_x000D_\\n요증상(-), edema(-), 요독증상(-), D...   \n",
              "3  148/90/64_x000D_\\n요증상(-), edema mild_x000D_\\nC...   \n",
              "4  선생님 안녕하십니까_x000D_\\n_x000D_\\n상기 병명으로 입원하여 치료중인 ...   \n",
              "\n",
              "                       CC_trans  \\\n",
              "0                           NaN   \n",
              "1  ckd4, cr 2.26, egfr 29ml/min   \n",
              "2                          ckd4   \n",
              "3           cr 3.74, egfr 13.56   \n",
              "4               lab abnormality   \n",
              "\n",
              "                                            PI_trans  \\\n",
              "0  115-61-61 2023.5.10.Protein Protein Protein Pr...   \n",
              "1  130/61/69 There is no symptom, no edema, no dy...   \n",
              "2  153/75/85 There is no symptom, no edema, no di...   \n",
              "3  148/90/64 No symptoms, edema Mild CKD D/T ADPK...   \n",
              "4  I am hospitalized and treated with a disease n...   \n",
              "\n",
              "                                              record  \n",
              "0  115-61-61 2023.5.10.Protein Protein Protein Pr...  \n",
              "1  ckd4, cr 2.26, egfr 29ml/min. 130/61/69 There ...  \n",
              "2  ckd4. 153/75/85 There is no symptom, no edema,...  \n",
              "3  cr 3.74, egfr 13.56. 148/90/64 No symptoms, ed...  \n",
              "4  lab abnormality. I am hospitalized and treated...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-c71f4ebb-d408-4992-a80a-ae021997138d\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ICD10</th>\n",
              "      <th>CC</th>\n",
              "      <th>PI</th>\n",
              "      <th>CC_trans</th>\n",
              "      <th>PI_trans</th>\n",
              "      <th>record</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>N391</td>\n",
              "      <td>NaN</td>\n",
              "      <td>115-61-61_x000D_\\n2023.5.10._x000D_\\n_x000D_\\n...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>115-61-61 2023.5.10.Protein Protein Protein Pr...</td>\n",
              "      <td>115-61-61 2023.5.10.Protein Protein Protein Pr...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>N184</td>\n",
              "      <td>CKD4, Cr 2.26, eGFR 29ml/min</td>\n",
              "      <td>130/61/69_x000D_\\n요증상(-), edema(-), 요독증상(-), D...</td>\n",
              "      <td>ckd4, cr 2.26, egfr 29ml/min</td>\n",
              "      <td>130/61/69 There is no symptom, no edema, no dy...</td>\n",
              "      <td>ckd4, cr 2.26, egfr 29ml/min. 130/61/69 There ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>N184</td>\n",
              "      <td>CKD4</td>\n",
              "      <td>153/75/85_x000D_\\n요증상(-), edema(-), 요독증상(-), D...</td>\n",
              "      <td>ckd4</td>\n",
              "      <td>153/75/85 There is no symptom, no edema, no di...</td>\n",
              "      <td>ckd4. 153/75/85 There is no symptom, no edema,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>N185</td>\n",
              "      <td>Cr 3.74, eGFR 13.56</td>\n",
              "      <td>148/90/64_x000D_\\n요증상(-), edema mild_x000D_\\nC...</td>\n",
              "      <td>cr 3.74, egfr 13.56</td>\n",
              "      <td>148/90/64 No symptoms, edema Mild CKD D/T ADPK...</td>\n",
              "      <td>cr 3.74, egfr 13.56. 148/90/64 No symptoms, ed...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>N183</td>\n",
              "      <td>lab abnormality</td>\n",
              "      <td>선생님 안녕하십니까_x000D_\\n_x000D_\\n상기 병명으로 입원하여 치료중인 ...</td>\n",
              "      <td>lab abnormality</td>\n",
              "      <td>I am hospitalized and treated with a disease n...</td>\n",
              "      <td>lab abnormality. I am hospitalized and treated...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c71f4ebb-d408-4992-a80a-ae021997138d')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-c71f4ebb-d408-4992-a80a-ae021997138d button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-c71f4ebb-d408-4992-a80a-ae021997138d');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-94edc4a1-96aa-4529-aa89-2431d34c6ea0\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-94edc4a1-96aa-4529-aa89-2431d34c6ea0')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-94edc4a1-96aa-4529-aa89-2431d34c6ea0 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 826,\n  \"fields\": [\n    {\n      \"column\": \"ICD10\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 14,\n        \"samples\": [\n          \"R311\",\n          \"Z524\",\n          \"N391\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"CC\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 214,\n        \"samples\": [\n          \"for evaluation of renal function\",\n          \"Cr 2.96, eGFR 23 ml/min, Hb 11.5, K 4.4\",\n          \"Cr 2.26, CKD stage 4\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"PI\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 815,\n        \"samples\": [\n          \" 2015.3.30  ECMP CAG and PCI (pLAD) IABP-CPR_x000D_\\n\\uc2dc\\ud589\\ud55c \\ubc14 \\uc788\\uc74c   \\uc0c1\\uae30 \\ud658\\uc790\\ub294 \\uc9c4\\ub2e8\\uba85[AMI](\\uc73c)\\ub85c \\ud604\\uc7ac \\uce58\\ub8cc\\uc911\\uc778 59\\uc138(M)\\uc758 \\ud658\\uc790\\uc785\\ub2c8\\ub2e4._x000D_\\n_x000D_\\ncr 1.65 --1.7 --1.87 --1.87 --1.98 --1.75 --2.05 --1.83 --1.87 --1.78 --1.88 -- 1.69 --1.83 _x000D_\\n1.78 --1.71 --1.69 --1.9 --1.56 --1.48 --1.68 --1.59 -1.64 _x000D_\\n_x000D_\\n\\uc2e0\\uae30\\ub2a5 \\uc800\\ud558\\ub85c \\uc758\\ub8b0\\ub428_x000D_\\n_x000D_\\nCKD --\\uc758\\ub8b0 \\ub4dc\\ub9bc _x000D_\\n_x000D_\\n_x000D_\\nAKI severe \\uc774\\ud6c4 (2015\\ub144 \\ub2f9\\uc2dc HD # 7 ) \\uc2dc\\ud589\\ud568_x000D_\\nno urinary sx_x000D_\\n\",\n          \"\\ud3c9\\uc18c \\ube44\\ud0c0\\ubbfc\\uc81c \\ud3ec\\ud568 7~8\\uac00\\uc9c0 \\ubcf4\\uc870\\uc81c 3\\ub144 \\uc815\\ub3c4 \\ubcf5\\uc6a9\\ud574 \\uc624\\uc2ec._x000D_\\n\\ucd5c\\uadfc \\ud3ec\\ud56d\\uc131\\ubaa8\\ubcd1\\uc6d0 \\uac80\\uc0ac\\uc5d0\\uc11c \\uc2e0\\uae30\\ub2a5 \\uc800\\ud558, \\ub2e8\\ubc31\\ub1e8 \\uc18c\\uacac \\ub4e4\\uc5b4, \\uacfc\\uac70 \\uac80\\uc9c4 \\ubcd1\\uc6d0 \\uc7ac\\ud655\\uc778\\ud558\\ub2c8 \\uc2e0\\uae30\\ub2a5 \\uc800\\ud558 \\uc18c\\uacac \\uc788\\uc5c8\\ub2e4\\uace0 \\ub4e4\\uc73c\\uc2ec._x000D_\\nCr 1.48 U/A P 1+ RBC 0-2_x000D_\\n\\ud0c0\\ubcd1\\uc6d0 kidney USG+\",\n          \"\\uc2e0\\uacbd\\uc678\\uacfc\\uc5d0\\uc11c Aneurysmal clipping \\uc608\\uc815\\uc778 \\ubd84\\uc73c\\ub85c, Cr 1.34 \\ub85c \\uc758\\ub8b0_x000D_\\n_x000D_\\n2023.10.03\\uc77c \\uc2e0\\uacbd\\uc678\\uacfc \\uc785\\uc6d0\\ud558\\uc5ec \\uc218\\uc220 \\uc608\\uc815 _x000D_\\n_x000D_\\n141/80-83 _x000D_\\n_x000D_\\n\\ud0a4, \\ubab8\\ubb34\\uac8c :168cm/74kg _x000D_\\n_x000D_\\nGeneral condition : good _x000D_\\nECOG PS : 0 _x000D_\\n_x000D_\\nHTN : (+) _x000D_\\nDM : (+) _x000D_\\n\\ucd5c\\uadfc Cr \\uc218\\uce58 : 23.09.12 Cr 1.34, eGFR 54 _x000D_\\n_x000D_\\n\\ucd5c\\uadfc \\uac70\\ud488\\ub1e8, \\ud608\\ub1e8 :_x000D_\\n_x000D_\\n\\ubd80\\uc885, body weight change: none _x000D_\\n_x000D_\\nmedication : (+) _x000D_\\n_x000D_\\n\\ud55c\\uc57d, \\uac74\\uac15\\ubcf4\\uc870\\uc2dd\\ud488, \\ub2f3\\uc778\\ubb3c, \\uc999 : none _x000D_\\n_x000D_\\nLMC lab \\uacb0\\uacfc\\uc9c0 or \\ucd5c\\uadfc 3-6\\uac1c\\uc6d4 \\uc2e0\\uc7a5 \\ud06c\\ub808\\uc544\\ud2f0\\ub2cc \\uacb0\\uacfc\\uc9c0  : \\uc2e0\\ubd80\\uc804\\uc774 \\uc788\\ub2e4\\uace0 \\ub4e4\\uc5c8\\ub2e4, \\uc57d 5-10\\ub144 \\uc804\\ubd80\\ud130 \\uc2e0\\uae30\\ub2a5\\uc774 \\uc548\\uc88b\\ub2e4\\uace0 \\ub4e4\\uc5c8\\uc74c _x000D_\\n_x000D_\\n\\uc548\\uacfc \\uc9c4\\ub8cc : 2022\\ub144 \\uc548\\uacfc \\uac80\\uc9c4 \\uc2dc\\ud589\\ud55c \\uc774\\ub825 \\uc788\\uc74c (\\ubc31\\ub0b4\\uc7a5\\uc774 \\uc788\\ub2e4\\uace0 \\ub4e4\\uc5c8\\uace0, \\uc218\\uc220 \\ud55c \\uc774\\ub825 \\uc788\\uc74c) _x000D_\\n_x000D_\\n\\uc2e0\\ubd80\\uc804 \\uac00\\uc871\\ub825 : none _x000D_\\n_x000D_\\n\\ucee8\\ub514\\uc158\\uc740 \\uc88b\\ub2e4, \\uc2dd\\uc0ac\\ub294 \\uc798\\ud55c\\ub2e4 _x000D_\\n_x000D_\\n\\ud3c9\\uc18c\\uc5d0 \\uc9dc\\uac8c \\uba39\\ub294\\ub2e4 _x000D_\\n_x000D_\\n_x000D_\\n\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"CC_trans\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 175,\n        \"samples\": [\n          \"microscopic\",\n          \"general edema\",\n          \"pre op cst\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"PI_trans\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 816,\n        \"samples\": [\n          \"2015.3.30 ECMP CAG PCI (PLAD) IABP-CPR is performed.CR 1.65 --1.7 -1.87 -1.87 -1.87 --1.75 --2.05-2.05-1.83 --1.87 -1.78-1.88- 1.69-1.83 1.78-1.71-1.69-1.9-1.56 --1.48 --1.68 -1.59-1.64 Requested by lowering new functions CKD -Request AKI SEVERE (HD in 2015 NO URINARY\",\n          \"Take 7 to 8 supplements for 3 years, including vitamins.Pohang St. Mary's Hospital, I heard that it was reduced by reducing renal function, proteinuria, and reaffirming.CR 1.48 U/A 1+ RBC 0-2 Other Hospital Kidney USG+\",\n          \"106/63/71 No edema, no foaming, no symptoms, no GH, 2023.10 for the first time in proteinuria.LMC inspection was CR 1.36, EGFR 44, Protein 1+, PCR 0.21 findings.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"record\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 816,\n        \"samples\": [\n          \"for evaluation renal function. 2015.3.30 ECMP CAG PCI (PLAD) IABP-CPR is performed.CR 1.65 --1.7 -1.87 -1.87 -1.87 --1.75 --2.05-2.05-1.83 --1.87 -1.78-1.88- 1.69-1.83 1.78-1.71-1.69-1.9-1.56 --1.48 --1.68 -1.59-1.64 Requested by lowering new functions CKD -Request AKI SEVERE (HD in 2015 NO URINARY\",\n          \"Reminery decrease, proteinuria. Take 7 to 8 supplements for 3 years, including vitamins.Pohang St. Mary's Hospital, I heard that it was reduced by reducing renal function, proteinuria, and reaffirming.CR 1.48 U/A 1+ RBC 0-2 Other Hospital Kidney USG+\",\n          \"cr 1.36, egfr 44, protein 1+, pcr 0.21. 106/63/71 No edema, no foaming, no symptoms, no GH, 2023.10 for the first time in proteinuria.LMC inspection was CR 1.36, EGFR 44, Protein 1+, PCR 0.21 findings.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "file_path = '/content/target_df.xlsx'\n",
        "# file_path = \"D:\\\\sample\\\\content\\\\신장내과_본원_외래_20230701_20231231_filtered.xlsx\"\n",
        "\n",
        "# selected_columns = ['ICD10', 'transstr']\n",
        "selected_columns = ['ICD10', 'CC', 'PI', 'CC_trans', 'PI_trans', 'record']\n",
        "df = pd.read_excel(file_path, usecols=selected_columns, dtype=str)\n",
        "\n",
        "print('전체 데이터 수 :', len(df))\n",
        "df.head(5)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 전처리 1\n",
        "# df['CC_2'] = df['CC'].str.replace(\"_x000D_\\n\", \"\\n\")\n",
        "# df['CC_2'] = df['CC_2'].str.replace(\"_x000D_\\n\", \"\\n\")\n",
        "# df['CC_2'] = df['CC_2'].str.replace(\"(+)\", \" 있음\")\n",
        "# df['CC_2'] = df['CC_2'].str.replace(\"(-))\", \" 없음\")\n",
        "# df['CC_2'] = df['CC_2'].str.strip()\n",
        "\n",
        "# df['PI_2'] = df['PI'].str.replace(\"_x000D_\\n\", \"\\n\")\n",
        "# df['PI_2'] = df['PI_2'].str.replace(\"(+)\", \" 있음\")\n",
        "# df['PI_2'] = df['PI_2'].str.replace(\"(-)\", \" 없음\")\n",
        "# df['PI_2'] = df['PI_2'].str.strip()\n",
        "\n",
        "# # df['HX_2'] = df['HX'].str.replace(\"_x000D_\\n\", \" \")\n",
        "# # df['HX_2'] = df['HX_2'].str.strip()\n",
        "\n",
        "# df.head(5)"
      ],
      "metadata": {
        "id": "dzFHr8_EC5zb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# stopwords dataset load\n",
        "# sw_path = \"D:\\\\sample\\\\content2\\\\stopwords.xlsx\"\n",
        "sw_path = \"/content/stopwords.xlsx\"\n",
        "sw_df = pd.read_excel(sw_path)\n",
        "for i in range(len(sw_df)) :\n",
        "  stop_words = sw_df['stop words'].tolist()\n",
        "# print(stop_words)"
      ],
      "metadata": {
        "id": "fhDDsi3DC_cE"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def remove_nonAscii(text):\n",
        "    rtn = ''\n",
        "    if not pd.isna(text):\n",
        "        rtn = \"\".join(str for str in text if ord(str)<128)\n",
        "    return rtn\n",
        "\n",
        "def make_lower_case(text):\n",
        "    rtn = ''\n",
        "    if not pd.isna(text):\n",
        "        rtn = text.lower()\n",
        "    return rtn\n",
        "\n",
        "def remove_stop_words(text):\n",
        "    rtn = ''\n",
        "    if not pd.isna(text):\n",
        "        rtn = text.split()\n",
        "        rtn = [w for w in rtn if not w in stop_words]\n",
        "        rtn = \" \".join(rtn)\n",
        "    return rtn\n",
        "\n",
        "def remove_punctuation(text):\n",
        "    rtn = ''\n",
        "    if not pd.isna(text):\n",
        "        tokenizer = RegexpTokenizer(r'[a-zA-Z]+')\n",
        "        rtn = tokenizer.tokenize(text)\n",
        "        rtn = \" \".join(rtn)\n",
        "    return rtn\n",
        "\n",
        "def remove_others(text):\n",
        "    rtn = ''\n",
        "    if not pd.isna(text):\n",
        "        s_text = text.split()\n",
        "        s_list = []\n",
        "\n",
        "        for w in s_text:\n",
        "            if len(w) > 1:\n",
        "                s_list.append(w)\n",
        "        rtn = \" \".join(s_list)\n",
        "    return rtn"
      ],
      "metadata": {
        "id": "GoL_7vk0DK-d"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # df['CC_2'] = df['CC'].apply(remove_nonAscii)\n",
        "# df['CC_2'] = df['CC_2'].apply(make_lower_case)\n",
        "# df['CC_2'] = df['CC_2'].apply(remove_stop_words)\n",
        "# # df['CC_2'] = df['CC_2'].apply(remove_punctuation)\n",
        "# df['CC_2'] = df['CC_2'].apply(remove_others)\n",
        "\n",
        "# # df['PI_2'] = df['PI'].apply(remove_nonAscii)\n",
        "# df['PI_2'] = df['PI_2'].apply(make_lower_case)\n",
        "# df['PI_2'] = df['PI_2'].apply(remove_stop_words)\n",
        "# # df['PI_2'] = df['PI_2'].apply(remove_punctuation)\n",
        "# df['PI_2'] = df['PI_2'].apply(remove_others)"
      ],
      "metadata": {
        "id": "cIxk3FUHDNGa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jEXPtS6UBUci",
        "outputId": "468f2508-24b3-47b3-acd8-072372a86e13"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: googletrans==4.0.0-rc1 in c:\\users\\klab\\anaconda3\\lib\\site-packages (4.0.0rc1)\n",
            "Requirement already satisfied: httpx==0.13.3 in c:\\users\\klab\\anaconda3\\lib\\site-packages (from googletrans==4.0.0-rc1) (0.13.3)\n",
            "Requirement already satisfied: certifi in c:\\users\\klab\\anaconda3\\lib\\site-packages (from httpx==0.13.3->googletrans==4.0.0-rc1) (2024.2.2)\n",
            "Requirement already satisfied: hstspreload in c:\\users\\klab\\anaconda3\\lib\\site-packages (from httpx==0.13.3->googletrans==4.0.0-rc1) (2024.5.1)\n",
            "Requirement already satisfied: sniffio in c:\\users\\klab\\anaconda3\\lib\\site-packages (from httpx==0.13.3->googletrans==4.0.0-rc1) (1.3.0)\n",
            "Requirement already satisfied: chardet==3.* in c:\\users\\klab\\anaconda3\\lib\\site-packages (from httpx==0.13.3->googletrans==4.0.0-rc1) (3.0.4)\n",
            "Requirement already satisfied: idna==2.* in c:\\users\\klab\\anaconda3\\lib\\site-packages (from httpx==0.13.3->googletrans==4.0.0-rc1) (2.10)\n",
            "Requirement already satisfied: rfc3986<2,>=1.3 in c:\\users\\klab\\anaconda3\\lib\\site-packages (from httpx==0.13.3->googletrans==4.0.0-rc1) (1.5.0)\n",
            "Requirement already satisfied: httpcore==0.9.* in c:\\users\\klab\\anaconda3\\lib\\site-packages (from httpx==0.13.3->googletrans==4.0.0-rc1) (0.9.1)\n",
            "Requirement already satisfied: h11<0.10,>=0.8 in c:\\users\\klab\\anaconda3\\lib\\site-packages (from httpcore==0.9.*->httpx==0.13.3->googletrans==4.0.0-rc1) (0.9.0)\n",
            "Requirement already satisfied: h2==3.* in c:\\users\\klab\\anaconda3\\lib\\site-packages (from httpcore==0.9.*->httpx==0.13.3->googletrans==4.0.0-rc1) (3.2.0)\n",
            "Requirement already satisfied: hyperframe<6,>=5.2.0 in c:\\users\\klab\\anaconda3\\lib\\site-packages (from h2==3.*->httpcore==0.9.*->httpx==0.13.3->googletrans==4.0.0-rc1) (5.2.0)\n",
            "Requirement already satisfied: hpack<4,>=3.0 in c:\\users\\klab\\anaconda3\\lib\\site-packages (from h2==3.*->httpcore==0.9.*->httpx==0.13.3->googletrans==4.0.0-rc1) (3.0.0)\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "# pip install googletrans==4.0.0-rc1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DaLPuYGgBUci"
      },
      "outputs": [],
      "source": [
        "# 번역\n",
        "# from googletrans import Translator\n",
        "\n",
        "# def trans_hng_to_eng(text):\n",
        "#     translator = Translator()\n",
        "#     if not text:  # None, 빈 문자열 모두 체크\n",
        "#         return None\n",
        "#     try:\n",
        "#         translated = translator.translate(text, dest='en')\n",
        "#         return translated.text\n",
        "#     except Exception as e:\n",
        "#         print(f\"Translation error: {e}\")\n",
        "#         return text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PP44tKY_BUci",
        "outputId": "f170225e-6d58-4009-a376-9330220862cb"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'CKD4, Cr 2.26, eGFR 29ml/min'"
            ]
          },
          "execution_count": 95,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# trans_hng_to_eng(df['주호소'][1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5I3pp6fvBUcj",
        "outputId": "7f6b0006-fe11-4c7e-f79f-4c14cf8efac8"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0                                \n",
              "1    CKD4, Cr 2.26, eGFR 29ml/min\n",
              "2                            CKD4\n",
              "3             Cr 3.74, eGFR 13.56\n",
              "4                 lab abnormality\n",
              "Name: CC_trans, dtype: object"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# df['transstr'] = df['현병력'].apply(trans_hng_to_eng)\n",
        "# df['transstr'][:5]\n",
        "\n",
        "# df['CC_trans'] = df['주호소'].apply(trans_hng_to_eng)\n",
        "# df['CC_trans'][:5]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qpnPw5TLBUcj"
      },
      "outputs": [],
      "source": [
        "# def combine_columns(col_1, col_2):\n",
        "#     result = ''\n",
        "\n",
        "#     if col_1:\n",
        "#         result = str(col_1).strip() + '.'\n",
        "\n",
        "#     if col_2:\n",
        "#         result += ' ' + str(col_2).strip()\n",
        "\n",
        "#     return result.strip()\n",
        "\n",
        "# df[\"record\"] = df.apply(lambda x: combine_columns(x['CC_trans'], x['PI_trans']), axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pz-Ez1VNBUcj",
        "outputId": "399318d6-5530-4e1c-d8af-dadf959761f7"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ICD10</th>\n",
              "      <th>주호소</th>\n",
              "      <th>PI_trans</th>\n",
              "      <th>CC_trans</th>\n",
              "      <th>record</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>N391</td>\n",
              "      <td>NaN</td>\n",
              "      <td>115-61-61 2023.5.10.Suspicion of proteinuria i...</td>\n",
              "      <td></td>\n",
              "      <td>115-61-61 2023.5.10.Suspicion of proteinuria ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>N184</td>\n",
              "      <td>CKD4, Cr 2.26, eGFR 29ml/min</td>\n",
              "      <td>130/61/69 Symptoms (-), edema (-), urbanic sym...</td>\n",
              "      <td>CKD4, Cr 2.26, eGFR 29ml/min</td>\n",
              "      <td>CKD4, Cr 2.26, eGFR 29ml/min 130/61/69 Symptom...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>N184</td>\n",
              "      <td>CKD4</td>\n",
              "      <td>153/75/85 osophy (-), edema (-), urinary sympt...</td>\n",
              "      <td>CKD4</td>\n",
              "      <td>CKD4 153/75/85 osophy (-), edema (-), urinary ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>N185</td>\n",
              "      <td>Cr 3.74, eGFR 13.56</td>\n",
              "      <td>148/90/64 Idema Mild CKD D/T ADPKD has been tr...</td>\n",
              "      <td>Cr 3.74, eGFR 13.56</td>\n",
              "      <td>Cr 3.74, eGFR 13.56 148/90/64 Idema Mild CKD D...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>N183</td>\n",
              "      <td>lab abnormality</td>\n",
              "      <td>Hello teacher, I am a patient who is being hos...</td>\n",
              "      <td>lab abnormality</td>\n",
              "      <td>lab abnormality Hello teacher, I am a patient ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>821</th>\n",
              "      <td>N183</td>\n",
              "      <td>Azotemia</td>\n",
              "      <td>136/73-73 23.02 EDEMA occurs after shoulder su...</td>\n",
              "      <td>Azotemia</td>\n",
              "      <td>Azotemia 136/73-73 23.02 EDEMA occurs after sh...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>822</th>\n",
              "      <td>N184</td>\n",
              "      <td>Azotemia</td>\n",
              "      <td>The patient is a diagnostic [DJD] patient of 8...</td>\n",
              "      <td>Azotemia</td>\n",
              "      <td>Azotemia The patient is a diagnostic [DJD] pat...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>823</th>\n",
              "      <td>N185</td>\n",
              "      <td>konos 등록</td>\n",
              "      <td>KONOS Registration HD 3 times a week, gold at ...</td>\n",
              "      <td>KONOS registration</td>\n",
              "      <td>KONOS registration KONOS Registration HD 3 tim...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>824</th>\n",
              "      <td>R601</td>\n",
              "      <td>Generalized edema</td>\n",
              "      <td>He has been edema two months ago.Urine comes o...</td>\n",
              "      <td>Generalized edema</td>\n",
              "      <td>Generalized edema He has been edema two months...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>825</th>\n",
              "      <td>N185</td>\n",
              "      <td>CAPD</td>\n",
              "      <td>Start at CAPD Yeungnam University in 2021 ESKD...</td>\n",
              "      <td>Capd</td>\n",
              "      <td>Capd Start at CAPD Yeungnam University in 2021...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>826 rows × 5 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "    ICD10                           주호소  \\\n",
              "0    N391                           NaN   \n",
              "1    N184  CKD4, Cr 2.26, eGFR 29ml/min   \n",
              "2    N184                          CKD4   \n",
              "3    N185           Cr 3.74, eGFR 13.56   \n",
              "4    N183               lab abnormality   \n",
              "..    ...                           ...   \n",
              "821  N183                      Azotemia   \n",
              "822  N184                      Azotemia   \n",
              "823  N185                      konos 등록   \n",
              "824  R601             Generalized edema   \n",
              "825  N185                          CAPD   \n",
              "\n",
              "                                              PI_trans  \\\n",
              "0    115-61-61 2023.5.10.Suspicion of proteinuria i...   \n",
              "1    130/61/69 Symptoms (-), edema (-), urbanic sym...   \n",
              "2    153/75/85 osophy (-), edema (-), urinary sympt...   \n",
              "3    148/90/64 Idema Mild CKD D/T ADPKD has been tr...   \n",
              "4    Hello teacher, I am a patient who is being hos...   \n",
              "..                                                 ...   \n",
              "821  136/73-73 23.02 EDEMA occurs after shoulder su...   \n",
              "822  The patient is a diagnostic [DJD] patient of 8...   \n",
              "823  KONOS Registration HD 3 times a week, gold at ...   \n",
              "824  He has been edema two months ago.Urine comes o...   \n",
              "825  Start at CAPD Yeungnam University in 2021 ESKD...   \n",
              "\n",
              "                         CC_trans  \\\n",
              "0                                   \n",
              "1    CKD4, Cr 2.26, eGFR 29ml/min   \n",
              "2                            CKD4   \n",
              "3             Cr 3.74, eGFR 13.56   \n",
              "4                 lab abnormality   \n",
              "..                            ...   \n",
              "821                      Azotemia   \n",
              "822                      Azotemia   \n",
              "823            KONOS registration   \n",
              "824             Generalized edema   \n",
              "825                          Capd   \n",
              "\n",
              "                                                record  \n",
              "0     115-61-61 2023.5.10.Suspicion of proteinuria ...  \n",
              "1    CKD4, Cr 2.26, eGFR 29ml/min 130/61/69 Symptom...  \n",
              "2    CKD4 153/75/85 osophy (-), edema (-), urinary ...  \n",
              "3    Cr 3.74, eGFR 13.56 148/90/64 Idema Mild CKD D...  \n",
              "4    lab abnormality Hello teacher, I am a patient ...  \n",
              "..                                                 ...  \n",
              "821  Azotemia 136/73-73 23.02 EDEMA occurs after sh...  \n",
              "822  Azotemia The patient is a diagnostic [DJD] pat...  \n",
              "823  KONOS registration KONOS Registration HD 3 tim...  \n",
              "824  Generalized edema He has been edema two months...  \n",
              "825  Capd Start at CAPD Yeungnam University in 2021...  \n",
              "\n",
              "[826 rows x 5 columns]"
            ]
          },
          "execution_count": 26,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# df.apply\n",
        "# df['record'].head(10)\n",
        "df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SxMXKPNg5Jx_",
        "outputId": "e1142c36-4741-49c2-f85d-5208c5f5057c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "431    azotemia. The patient is a patient of 84 years...\n",
            "263    azotemia. I have never checked it before 2023....\n",
            "786    azotemia. Four years ago, HTN was confirmed in...\n",
            "331    hematuria. Hematuria Clot occurred from HTN, D...\n",
            "760    proteinuria. No HTN, no DM No MDS F/U In the t...\n",
            "                             ...                        \n",
            "258    112-56-78 Vomiting of pruritus vomiting vsd Cl...\n",
            "58     hematuria. Hematuria is heard from the 20s and...\n",
            "518    hematuria. 2023. Listen to hematuria.Gross Hem...\n",
            "417    2016년 cr 1.9, 2023.6 cr 1.6mg/dl. 139/88/88 No...\n",
            "163                                            121-65-91\n",
            "Name: record, Length: 578, dtype: object\n",
            "=======================================\n",
            "\n",
            "161    proteinuria. OLD ICH, RT BG HTN (I knew it bef...\n",
            "30     for evaluation persistent proteinuria. From ar...\n",
            "20     116-72-67 Hypertension 4-year Gallens Cypse Pi...\n",
            "766    130-84-103 dm dm retinopathy (avastin laser) 2...\n",
            "39     Reminery decrease. 2017. CR 0.89 EGFR 85 U/A P...\n",
            "                             ...                        \n",
            "274    donor. Kwak Jae -sung (3654758) Mrs. Kwang -su...\n",
            "612    microscopic hematuria proteinuria. Rou R/O Art...\n",
            "726    Proteinuria. Albuminuria's findings from 2021 ...\n",
            "515    Reduction of renal function. HTN (20Y) joint, ...\n",
            "390    egfr 49. CVA (2022.) htn (2022.) DL proteinuri...\n",
            "Name: record, Length: 124, dtype: object\n",
            "=======================================\n",
            "\n",
            "599    will know. 135/98-125 Brain Lion Lion Training...\n",
            "482    cr 1.89, ckd management. 133/78/82 There is no...\n",
            "643    Proteinuria, hematuria. 2023. For the first ti...\n",
            "214    hematuria. Hematuria lasted last year, so ther...\n",
            "425    hematuria. 2022.11.08 There was no hematuria w...\n",
            "                             ...                        \n",
            "85     hematuria, proteinuria. 2 years ago, the prote...\n",
            "171    azotemia. The patient is a patient of 89 years...\n",
            "677    azotemia. Wound Infection S/P PLIF State L3-4-...\n",
            "401    azotemia. 2023.08.28 CR 1.42, EGFR 47.7, UPCR ...\n",
            "804    azotemia. The patient is a patient of 51 years...\n",
            "Name: record, Length: 124, dtype: object\n",
            "=======================================\n",
            "\n",
            "431    N183\n",
            "263    N178\n",
            "786    N183\n",
            "331    N029\n",
            "760    R808\n",
            "       ... \n",
            "258    N182\n",
            "58     N029\n",
            "518    N029\n",
            "417    N183\n",
            "163    Z524\n",
            "Name: ICD10, Length: 578, dtype: object\n",
            "=======================================\n",
            "\n",
            "161    R808\n",
            "30     N391\n",
            "20     N183\n",
            "766    N183\n",
            "39     N183\n",
            "       ... \n",
            "274    Z524\n",
            "612    R311\n",
            "726    N391\n",
            "515    N185\n",
            "390    N183\n",
            "Name: ICD10, Length: 124, dtype: object\n",
            "=======================================\n",
            "\n",
            "599    N185\n",
            "482    N183\n",
            "643    N059\n",
            "214    N029\n",
            "425    N029\n",
            "       ... \n",
            "85     N391\n",
            "171    N183\n",
            "677    N183\n",
            "401    N059\n",
            "804    N178\n",
            "Name: ICD10, Length: 124, dtype: object\n"
          ]
        }
      ],
      "source": [
        "# 학습용, 테스트용, 검증용 데이터 분할\n",
        "X_train, X_temp, y_train, y_temp = train_test_split(df['record'], df['ICD10'], test_size=0.3, shuffle=True, random_state=52, stratify=df['ICD10'])\n",
        "X_test, X_val, y_test, y_val = train_test_split(X_temp, y_temp, test_size=0.5, shuffle=True, random_state=73, stratify=y_temp)\n",
        "\n",
        "# X_train, X_temp, y_train, y_temp = train_test_split(df['record'], df['ICD10'], test_size=0.2, random_state=None, stratify=df['ICD10'])\n",
        "# X_test, X_val, y_test, y_val = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42, stratify=y_temp)\n",
        "\n",
        "print(X_train)\n",
        "print(\"=======================================\\n\")\n",
        "print(X_test)\n",
        "print(\"=======================================\\n\")\n",
        "print(X_val)\n",
        "print(\"=======================================\\n\")\n",
        "print(y_train)\n",
        "print(\"=======================================\\n\")\n",
        "print(y_test)\n",
        "print(\"=======================================\\n\")\n",
        "print(y_val)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "### datasets 분할 확인\n",
        "y_train_counts =  y_train.value_counts()\n",
        "y_test_counts = y_test.value_counts()\n",
        "y_val_counts = y_val.value_counts()\n",
        "\n",
        "y_train_counts_df = y_train_counts.reset_index()\n",
        "y_train_counts_df.columns = ['ICD10', 'y_train_count']\n",
        "y_test_counts_df = y_test_counts.reset_index()\n",
        "y_test_counts_df.columns = ['ICD10', 'y_test_count']\n",
        "y_val_counts_df = y_val_counts.reset_index()\n",
        "y_val_counts_df.columns = ['ICD10', 'y_val_count']\n",
        "\n",
        "# 두 DataFrame을 병합\n",
        "counts_df = pd.merge(y_train_counts_df, y_test_counts_df, on='ICD10', how='outer').fillna(0)\n",
        "counts_df = pd.merge(counts_df, y_val_counts_df, on='ICD10', how='outer').fillna(0)\n",
        "\n",
        "# 정수형으로 변환 (NaN 처리 후)\n",
        "counts_df['y_train_count'] = counts_df['y_train_count'].astype(int)\n",
        "counts_df['y_test_count'] = counts_df['y_test_count'].astype(int)\n",
        "counts_df['y_val_count'] = counts_df['y_val_count'].astype(int)\n",
        "\n",
        "print(counts_df)\n",
        "### End of datasets 분할 확인"
      ],
      "metadata": {
        "id": "w4krc8HTDnRb",
        "outputId": "f2b1c0dc-46af-47d6-b012-4b8bb6fb8dc2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   ICD10  y_train_count  y_test_count  y_val_count\n",
            "0   N183            197            43           42\n",
            "1   N185             74            16           16\n",
            "2   N184             43             9            9\n",
            "3   N391             41             9            9\n",
            "4   N178             39             8            9\n",
            "5   R311             36             8            8\n",
            "6   N029             29             7            6\n",
            "7   R798             24             6            5\n",
            "8   Z524             22             4            5\n",
            "9   N182             20             4            4\n",
            "10  N059             19             4            4\n",
            "11  N028             12             2            3\n",
            "12  R808             11             2            2\n",
            "13  R601             11             2            2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Categorical encoding\n",
        "label_dict = df['ICD10'].unique()\n",
        "print(\"labels :\", label_dict)\n",
        "category = label_dict.reshape(-1, 1)\n",
        "\n",
        "# label one-hot-encoding\n",
        "onehot_encoder = OneHotEncoder() #sparse_output=False\n",
        "\n",
        "# fit_transform은 train에만 사용하고 test에는 학습된 인코더에 fit만 해야한다\n",
        "y_train_encoded = onehot_encoder.fit_transform(pd.DataFrame(y_train)[['ICD10']])\n",
        "y_test_encoded = onehot_encoder.transform(pd.DataFrame(y_test)[['ICD10']])\n",
        "y_val_encoded = onehot_encoder.transform(pd.DataFrame(y_val)[['ICD10']])\n",
        "\n",
        "print(y_train_encoded.toarray())"
      ],
      "metadata": {
        "id": "DqhVYdylDqRE",
        "outputId": "f22f213a-0fea-43ea-f022-fb69c105b3b1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "labels : ['N391' 'N184' 'N185' 'N183' 'N029' 'N182' 'N178' 'R798' 'R808' 'R311'\n",
            " 'N059' 'Z524' 'N028' 'R601']\n",
            "[[0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " ...\n",
            " [0. 1. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 1.]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(label_dict)"
      ],
      "metadata": {
        "id": "d9J3uyAOhI_Y",
        "outputId": "b13b02e6-6f86-410d-a32d-7baf5818e1f9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "14"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "onehot_encoder.categories_"
      ],
      "metadata": {
        "collapsed": true,
        "id": "ezq8h5TFDuIu",
        "outputId": "2f55db82-64a4-4728-cbbd-07d6aaaa00d7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[array(['N028', 'N029', 'N059', 'N178', 'N182', 'N183', 'N184', 'N185',\n",
              "        'N391', 'R311', 'R601', 'R798', 'R808', 'Z524'], dtype=object)]"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "onehot_encoder.inverse_transform(y_train_encoded)"
      ],
      "metadata": {
        "collapsed": true,
        "id": "opsGQy7EDurM",
        "outputId": "3e3a5c65-3836-4836-cfe8-03dcc1b9d503",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([['N183'],\n",
              "       ['N178'],\n",
              "       ['N183'],\n",
              "       ['N029'],\n",
              "       ['R808'],\n",
              "       ['N391'],\n",
              "       ['N184'],\n",
              "       ['N183'],\n",
              "       ['N183'],\n",
              "       ['N183'],\n",
              "       ['N183'],\n",
              "       ['N183'],\n",
              "       ['N185'],\n",
              "       ['N185'],\n",
              "       ['N183'],\n",
              "       ['N183'],\n",
              "       ['N185'],\n",
              "       ['R311'],\n",
              "       ['R798'],\n",
              "       ['N185'],\n",
              "       ['N183'],\n",
              "       ['N184'],\n",
              "       ['N183'],\n",
              "       ['N183'],\n",
              "       ['N391'],\n",
              "       ['N059'],\n",
              "       ['N183'],\n",
              "       ['N183'],\n",
              "       ['N183'],\n",
              "       ['R808'],\n",
              "       ['N028'],\n",
              "       ['R601'],\n",
              "       ['N178'],\n",
              "       ['N184'],\n",
              "       ['N178'],\n",
              "       ['N182'],\n",
              "       ['N391'],\n",
              "       ['N185'],\n",
              "       ['N185'],\n",
              "       ['N183'],\n",
              "       ['N182'],\n",
              "       ['N183'],\n",
              "       ['Z524'],\n",
              "       ['Z524'],\n",
              "       ['N185'],\n",
              "       ['N183'],\n",
              "       ['N185'],\n",
              "       ['N183'],\n",
              "       ['N183'],\n",
              "       ['N029'],\n",
              "       ['R311'],\n",
              "       ['N183'],\n",
              "       ['Z524'],\n",
              "       ['N183'],\n",
              "       ['R311'],\n",
              "       ['N183'],\n",
              "       ['N185'],\n",
              "       ['N183'],\n",
              "       ['N183'],\n",
              "       ['N029'],\n",
              "       ['N185'],\n",
              "       ['N183'],\n",
              "       ['N183'],\n",
              "       ['N183'],\n",
              "       ['N391'],\n",
              "       ['N028'],\n",
              "       ['N183'],\n",
              "       ['N059'],\n",
              "       ['R311'],\n",
              "       ['N391'],\n",
              "       ['N182'],\n",
              "       ['N183'],\n",
              "       ['N028'],\n",
              "       ['R601'],\n",
              "       ['N029'],\n",
              "       ['N178'],\n",
              "       ['N183'],\n",
              "       ['N183'],\n",
              "       ['N183'],\n",
              "       ['N182'],\n",
              "       ['N185'],\n",
              "       ['N391'],\n",
              "       ['N029'],\n",
              "       ['N183'],\n",
              "       ['N183'],\n",
              "       ['N184'],\n",
              "       ['N183'],\n",
              "       ['N029'],\n",
              "       ['R798'],\n",
              "       ['N183'],\n",
              "       ['Z524'],\n",
              "       ['N183'],\n",
              "       ['N183'],\n",
              "       ['N183'],\n",
              "       ['N183'],\n",
              "       ['Z524'],\n",
              "       ['N183'],\n",
              "       ['N185'],\n",
              "       ['N183'],\n",
              "       ['N178'],\n",
              "       ['N028'],\n",
              "       ['N183'],\n",
              "       ['N178'],\n",
              "       ['N178'],\n",
              "       ['N183'],\n",
              "       ['N183'],\n",
              "       ['N183'],\n",
              "       ['N183'],\n",
              "       ['N178'],\n",
              "       ['N185'],\n",
              "       ['N184'],\n",
              "       ['N183'],\n",
              "       ['N391'],\n",
              "       ['R798'],\n",
              "       ['N185'],\n",
              "       ['N183'],\n",
              "       ['N391'],\n",
              "       ['N183'],\n",
              "       ['N183'],\n",
              "       ['N183'],\n",
              "       ['N184'],\n",
              "       ['N183'],\n",
              "       ['N183'],\n",
              "       ['R798'],\n",
              "       ['R798'],\n",
              "       ['Z524'],\n",
              "       ['N184'],\n",
              "       ['N183'],\n",
              "       ['N059'],\n",
              "       ['N183'],\n",
              "       ['N391'],\n",
              "       ['N178'],\n",
              "       ['N391'],\n",
              "       ['N183'],\n",
              "       ['R601'],\n",
              "       ['R601'],\n",
              "       ['R311'],\n",
              "       ['R311'],\n",
              "       ['N185'],\n",
              "       ['R601'],\n",
              "       ['N183'],\n",
              "       ['N184'],\n",
              "       ['N178'],\n",
              "       ['N178'],\n",
              "       ['N185'],\n",
              "       ['N183'],\n",
              "       ['N184'],\n",
              "       ['N391'],\n",
              "       ['N183'],\n",
              "       ['N029'],\n",
              "       ['N183'],\n",
              "       ['N184'],\n",
              "       ['N183'],\n",
              "       ['N185'],\n",
              "       ['N185'],\n",
              "       ['N182'],\n",
              "       ['N183'],\n",
              "       ['N185'],\n",
              "       ['N183'],\n",
              "       ['N391'],\n",
              "       ['N059'],\n",
              "       ['N185'],\n",
              "       ['R798'],\n",
              "       ['N182'],\n",
              "       ['N178'],\n",
              "       ['N178'],\n",
              "       ['N183'],\n",
              "       ['Z524'],\n",
              "       ['N184'],\n",
              "       ['N183'],\n",
              "       ['N183'],\n",
              "       ['N185'],\n",
              "       ['N183'],\n",
              "       ['N185'],\n",
              "       ['N183'],\n",
              "       ['R311'],\n",
              "       ['N183'],\n",
              "       ['N183'],\n",
              "       ['R311'],\n",
              "       ['N391'],\n",
              "       ['N183'],\n",
              "       ['N183'],\n",
              "       ['N178'],\n",
              "       ['N178'],\n",
              "       ['Z524'],\n",
              "       ['N185'],\n",
              "       ['N178'],\n",
              "       ['N029'],\n",
              "       ['N185'],\n",
              "       ['N183'],\n",
              "       ['N183'],\n",
              "       ['N183'],\n",
              "       ['N059'],\n",
              "       ['N183'],\n",
              "       ['N183'],\n",
              "       ['R311'],\n",
              "       ['N183'],\n",
              "       ['N183'],\n",
              "       ['N183'],\n",
              "       ['N028'],\n",
              "       ['N183'],\n",
              "       ['N178'],\n",
              "       ['Z524'],\n",
              "       ['N183'],\n",
              "       ['N184'],\n",
              "       ['R798'],\n",
              "       ['N183'],\n",
              "       ['N059'],\n",
              "       ['N183'],\n",
              "       ['N184'],\n",
              "       ['N183'],\n",
              "       ['N183'],\n",
              "       ['R798'],\n",
              "       ['N185'],\n",
              "       ['N183'],\n",
              "       ['N028'],\n",
              "       ['R798'],\n",
              "       ['N059'],\n",
              "       ['R601'],\n",
              "       ['N185'],\n",
              "       ['N178'],\n",
              "       ['N178'],\n",
              "       ['N183'],\n",
              "       ['N059'],\n",
              "       ['N182'],\n",
              "       ['N184'],\n",
              "       ['N183'],\n",
              "       ['N183'],\n",
              "       ['N184'],\n",
              "       ['N029'],\n",
              "       ['N183'],\n",
              "       ['N391'],\n",
              "       ['N183'],\n",
              "       ['Z524'],\n",
              "       ['N183'],\n",
              "       ['N185'],\n",
              "       ['N183'],\n",
              "       ['N028'],\n",
              "       ['R311'],\n",
              "       ['N028'],\n",
              "       ['N184'],\n",
              "       ['N059'],\n",
              "       ['N391'],\n",
              "       ['N183'],\n",
              "       ['R311'],\n",
              "       ['N183'],\n",
              "       ['N185'],\n",
              "       ['N029'],\n",
              "       ['N183'],\n",
              "       ['N185'],\n",
              "       ['N178'],\n",
              "       ['N183'],\n",
              "       ['N391'],\n",
              "       ['Z524'],\n",
              "       ['R601'],\n",
              "       ['N184'],\n",
              "       ['N391'],\n",
              "       ['N183'],\n",
              "       ['N183'],\n",
              "       ['N391'],\n",
              "       ['R601'],\n",
              "       ['N183'],\n",
              "       ['N183'],\n",
              "       ['R311'],\n",
              "       ['R798'],\n",
              "       ['N391'],\n",
              "       ['R311'],\n",
              "       ['N183'],\n",
              "       ['N183'],\n",
              "       ['N184'],\n",
              "       ['N391'],\n",
              "       ['N185'],\n",
              "       ['N183'],\n",
              "       ['R311'],\n",
              "       ['R311'],\n",
              "       ['N183'],\n",
              "       ['N184'],\n",
              "       ['Z524'],\n",
              "       ['N183'],\n",
              "       ['N182'],\n",
              "       ['N184'],\n",
              "       ['N185'],\n",
              "       ['Z524'],\n",
              "       ['R311'],\n",
              "       ['N178'],\n",
              "       ['N183'],\n",
              "       ['N178'],\n",
              "       ['N183'],\n",
              "       ['N029'],\n",
              "       ['R311'],\n",
              "       ['N183'],\n",
              "       ['N183'],\n",
              "       ['N183'],\n",
              "       ['N183'],\n",
              "       ['N185'],\n",
              "       ['N183'],\n",
              "       ['R311'],\n",
              "       ['R311'],\n",
              "       ['R808'],\n",
              "       ['N184'],\n",
              "       ['R798'],\n",
              "       ['N183'],\n",
              "       ['N185'],\n",
              "       ['N183'],\n",
              "       ['R311'],\n",
              "       ['N029'],\n",
              "       ['N029'],\n",
              "       ['N028'],\n",
              "       ['R808'],\n",
              "       ['N183'],\n",
              "       ['N183'],\n",
              "       ['N185'],\n",
              "       ['N183'],\n",
              "       ['Z524'],\n",
              "       ['N185'],\n",
              "       ['N183'],\n",
              "       ['N183'],\n",
              "       ['N184'],\n",
              "       ['N183'],\n",
              "       ['N184'],\n",
              "       ['N059'],\n",
              "       ['N183'],\n",
              "       ['N183'],\n",
              "       ['N391'],\n",
              "       ['N029'],\n",
              "       ['N185'],\n",
              "       ['N183'],\n",
              "       ['N185'],\n",
              "       ['N178'],\n",
              "       ['N184'],\n",
              "       ['R798'],\n",
              "       ['N391'],\n",
              "       ['N185'],\n",
              "       ['N029'],\n",
              "       ['N183'],\n",
              "       ['N184'],\n",
              "       ['N178'],\n",
              "       ['N185'],\n",
              "       ['N183'],\n",
              "       ['N183'],\n",
              "       ['N183'],\n",
              "       ['N183'],\n",
              "       ['R311'],\n",
              "       ['N183'],\n",
              "       ['N184'],\n",
              "       ['N184'],\n",
              "       ['N185'],\n",
              "       ['N178'],\n",
              "       ['N183'],\n",
              "       ['N183'],\n",
              "       ['N183'],\n",
              "       ['N391'],\n",
              "       ['R808'],\n",
              "       ['N183'],\n",
              "       ['N182'],\n",
              "       ['N185'],\n",
              "       ['R798'],\n",
              "       ['R311'],\n",
              "       ['N178'],\n",
              "       ['R798'],\n",
              "       ['N183'],\n",
              "       ['R311'],\n",
              "       ['N178'],\n",
              "       ['N185'],\n",
              "       ['N183'],\n",
              "       ['N185'],\n",
              "       ['N184'],\n",
              "       ['N185'],\n",
              "       ['N183'],\n",
              "       ['N391'],\n",
              "       ['N185'],\n",
              "       ['N185'],\n",
              "       ['N391'],\n",
              "       ['N183'],\n",
              "       ['N391'],\n",
              "       ['R798'],\n",
              "       ['N182'],\n",
              "       ['N185'],\n",
              "       ['N028'],\n",
              "       ['N185'],\n",
              "       ['N029'],\n",
              "       ['N185'],\n",
              "       ['R798'],\n",
              "       ['N028'],\n",
              "       ['N184'],\n",
              "       ['N182'],\n",
              "       ['N183'],\n",
              "       ['N183'],\n",
              "       ['R798'],\n",
              "       ['N183'],\n",
              "       ['N185'],\n",
              "       ['N059'],\n",
              "       ['N178'],\n",
              "       ['Z524'],\n",
              "       ['N183'],\n",
              "       ['N183'],\n",
              "       ['N183'],\n",
              "       ['R798'],\n",
              "       ['N029'],\n",
              "       ['N183'],\n",
              "       ['N185'],\n",
              "       ['R798'],\n",
              "       ['N182'],\n",
              "       ['N183'],\n",
              "       ['N185'],\n",
              "       ['N185'],\n",
              "       ['N183'],\n",
              "       ['N183'],\n",
              "       ['N029'],\n",
              "       ['N184'],\n",
              "       ['N029'],\n",
              "       ['N029'],\n",
              "       ['N183'],\n",
              "       ['N059'],\n",
              "       ['N183'],\n",
              "       ['R808'],\n",
              "       ['N183'],\n",
              "       ['N183'],\n",
              "       ['N183'],\n",
              "       ['N183'],\n",
              "       ['N391'],\n",
              "       ['R798'],\n",
              "       ['N183'],\n",
              "       ['Z524'],\n",
              "       ['N391'],\n",
              "       ['N391'],\n",
              "       ['R311'],\n",
              "       ['N029'],\n",
              "       ['Z524'],\n",
              "       ['N185'],\n",
              "       ['N182'],\n",
              "       ['N183'],\n",
              "       ['N184'],\n",
              "       ['R311'],\n",
              "       ['N184'],\n",
              "       ['N029'],\n",
              "       ['N183'],\n",
              "       ['N029'],\n",
              "       ['N185'],\n",
              "       ['N059'],\n",
              "       ['N183'],\n",
              "       ['N178'],\n",
              "       ['R311'],\n",
              "       ['N391'],\n",
              "       ['N391'],\n",
              "       ['N185'],\n",
              "       ['R311'],\n",
              "       ['N183'],\n",
              "       ['N028'],\n",
              "       ['R808'],\n",
              "       ['R808'],\n",
              "       ['N029'],\n",
              "       ['N184'],\n",
              "       ['Z524'],\n",
              "       ['N185'],\n",
              "       ['N184'],\n",
              "       ['N185'],\n",
              "       ['Z524'],\n",
              "       ['R798'],\n",
              "       ['N185'],\n",
              "       ['N178'],\n",
              "       ['N183'],\n",
              "       ['N185'],\n",
              "       ['R601'],\n",
              "       ['N182'],\n",
              "       ['N391'],\n",
              "       ['N391'],\n",
              "       ['N185'],\n",
              "       ['R311'],\n",
              "       ['R311'],\n",
              "       ['N184'],\n",
              "       ['N184'],\n",
              "       ['R311'],\n",
              "       ['N059'],\n",
              "       ['N391'],\n",
              "       ['N391'],\n",
              "       ['N183'],\n",
              "       ['N184'],\n",
              "       ['N182'],\n",
              "       ['N391'],\n",
              "       ['R601'],\n",
              "       ['N391'],\n",
              "       ['N183'],\n",
              "       ['N178'],\n",
              "       ['N183'],\n",
              "       ['R808'],\n",
              "       ['N183'],\n",
              "       ['N059'],\n",
              "       ['N178'],\n",
              "       ['N183'],\n",
              "       ['N182'],\n",
              "       ['N183'],\n",
              "       ['N182'],\n",
              "       ['N178'],\n",
              "       ['R311'],\n",
              "       ['N029'],\n",
              "       ['N183'],\n",
              "       ['N185'],\n",
              "       ['R311'],\n",
              "       ['N185'],\n",
              "       ['N183'],\n",
              "       ['N059'],\n",
              "       ['R808'],\n",
              "       ['N185'],\n",
              "       ['N183'],\n",
              "       ['N183'],\n",
              "       ['N183'],\n",
              "       ['N029'],\n",
              "       ['N184'],\n",
              "       ['R311'],\n",
              "       ['N059'],\n",
              "       ['R808'],\n",
              "       ['N391'],\n",
              "       ['N183'],\n",
              "       ['N185'],\n",
              "       ['N183'],\n",
              "       ['N391'],\n",
              "       ['N183'],\n",
              "       ['N184'],\n",
              "       ['Z524'],\n",
              "       ['N182'],\n",
              "       ['N178'],\n",
              "       ['N185'],\n",
              "       ['R798'],\n",
              "       ['N184'],\n",
              "       ['N183'],\n",
              "       ['N185'],\n",
              "       ['N178'],\n",
              "       ['N184'],\n",
              "       ['N185'],\n",
              "       ['N183'],\n",
              "       ['N178'],\n",
              "       ['R311'],\n",
              "       ['N183'],\n",
              "       ['N391'],\n",
              "       ['N182'],\n",
              "       ['N183'],\n",
              "       ['N183'],\n",
              "       ['N185'],\n",
              "       ['R311'],\n",
              "       ['N183'],\n",
              "       ['N183'],\n",
              "       ['N183'],\n",
              "       ['N185'],\n",
              "       ['N183'],\n",
              "       ['N059'],\n",
              "       ['N059'],\n",
              "       ['R798'],\n",
              "       ['R311'],\n",
              "       ['N183'],\n",
              "       ['N185'],\n",
              "       ['N029'],\n",
              "       ['Z524'],\n",
              "       ['N184'],\n",
              "       ['N184'],\n",
              "       ['N183'],\n",
              "       ['N185'],\n",
              "       ['N391'],\n",
              "       ['N185'],\n",
              "       ['R798'],\n",
              "       ['N183'],\n",
              "       ['N183'],\n",
              "       ['N183'],\n",
              "       ['N178'],\n",
              "       ['N183'],\n",
              "       ['N178'],\n",
              "       ['N183'],\n",
              "       ['N183'],\n",
              "       ['N183'],\n",
              "       ['N178'],\n",
              "       ['N183'],\n",
              "       ['N185'],\n",
              "       ['R601'],\n",
              "       ['N182'],\n",
              "       ['N029'],\n",
              "       ['N029'],\n",
              "       ['N183'],\n",
              "       ['Z524']], dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_train_dense = y_train_encoded.todense()\n",
        "y_test_dense = y_test_encoded.todense()\n",
        "y_val_dense = y_val_encoded.todense()"
      ],
      "metadata": {
        "id": "EVfshQ72DwC6"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XBi6fikpk2H9"
      },
      "outputs": [],
      "source": [
        "#https://zzaebok.github.io/deep_learning/nlp/Bert-for-classification/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3oYtGKnFYDhy"
      },
      "outputs": [],
      "source": [
        "class EMRDiagcdDataset(Dataset):\n",
        "\n",
        "    def __init__(self, df):\n",
        "        self.df = df\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.df)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        record = self.df.iloc[index]['record']\n",
        "        # diagcd = self.df.iloc[index]['ICD10']\n",
        "        diagcd = self.df.iloc[index]['encoded_ICD10']\n",
        "\n",
        "        return record, diagcd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sQY8jv0RBUck"
      },
      "outputs": [],
      "source": [
        "class EMRDiagcdDataset2(Dataset):\n",
        "    def __init__(self, dataset, sent_idx, label_idx, bert_tokenizer, vocab, max_len,\n",
        "                 pad, pair):\n",
        "\n",
        "        transform = nlp.data.BERTSentenceTransform(\n",
        "            bert_tokenizer, max_seq_length=max_len, vocab=vocab, pad=pad, pair=pair)\n",
        "\n",
        "        self.sentences = [transform([i[sent_idx]]) for i in dataset]\n",
        "        self.labels = [np.int32(i[label_idx]) for i in dataset]\n",
        "\n",
        "    def __getitem__(self, i):\n",
        "        return (self.sentences[i] + (self.labels[i], ))\n",
        "\n",
        "\n",
        "    def __len__(self):\n",
        "        return (len(self.labels))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class EMRDiagcdDataset3(Dataset):\n",
        "    def __init__(self, texts, labels, tokenizer, max_length):\n",
        "        self.texts = texts\n",
        "        self.labels = labels\n",
        "        self.tokenizer = tokenizer\n",
        "        self.max_length = max_length\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.texts)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        text = self.texts[idx]\n",
        "        label = self.labels[idx]\n",
        "        encoding = self.tokenizer(text, padding=True, truncation=True, max_length=self.max_length, return_tensors='pt')\n",
        "        return encoding, label"
      ],
      "metadata": {
        "id": "VLordXKThbL4"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_model(model, train_loader, optimizer, num_epochs):\n",
        "    for epoch in range(num_epochs):\n",
        "        running_loss = 0.0\n",
        "        for inputs, labels in train_loader:\n",
        "            optimizer.zero_grad()\n",
        "            labels = torch.tensor(labels, dtype=torch.float32)\n",
        "            outputs = model(**inputs, labels=labels)\n",
        "            loss = outputs.loss\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            running_loss += loss.item() * inputs['input_ids'].size(0)\n",
        "        epoch_loss = running_loss / len(train_loader.dataset)\n",
        "        print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {epoch_loss:.4f}\")"
      ],
      "metadata": {
        "id": "xtW1PSm0hoL4"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class UMLSBertCNN(nn.Module):\n",
        "    def __init__(self, bert_model_name, num_labels):\n",
        "        super(UMLSBertCNN, self).__init__()\n",
        "        self.bert = AutoModel.from_pretrained(bert_model_name)\n",
        "        self.cnn = nn.Conv1d(in_channels=self.bert.config.hidden_size, out_channels=128, kernel_size=3, padding=1)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.pool = nn.MaxPool1d(kernel_size=2, stride=2)\n",
        "        self.fc = nn.Linear(128 * (self.bert.config.max_position_embeddings // 2), num_labels)\n",
        "        self.sigmoid = nn.Sigmoid()\n",
        "\n",
        "    def forward(self, input_ids, attention_mask):\n",
        "        outputs = self.bert(input_ids=input_ids, attention_mask=attention_mask)\n",
        "        last_hidden_state = outputs.last_hidden_state\n",
        "        last_hidden_state = last_hidden_state.permute(0, 2, 1)  # (batch_size, hidden_size, seq_len)\n",
        "        cnn_output = self.cnn(last_hidden_state)  # (batch_size, 128, seq_len)\n",
        "        cnn_output = self.relu(cnn_output)\n",
        "        cnn_output = self.pool(cnn_output)  # (batch_size, 128, seq_len//2)\n",
        "        cnn_output = cnn_output.view(cnn_output.size(0), -1)  # flatten\n",
        "        logits = self.fc(cnn_output)  # (batch_size, num_labels)\n",
        "        output = self.sigmoid(logits)  # For multi-label classification\n",
        "        return output"
      ],
      "metadata": {
        "id": "tlP1I03eEPw0"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "max_len = 0\n",
        "\n",
        "for rowstr in df['record']:\n",
        "    if len(rowstr) > max_len:\n",
        "        max_len = len(rowstr)\n",
        "\n",
        "print(max_len)"
      ],
      "metadata": {
        "id": "YBpmchsxhUr1",
        "outputId": "f0839e0f-6735-4f64-ba13-699d84823e35",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1060\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load pre-trained tokenizer & model\n",
        "# bert_model_name = \"GanjinZero/UMLSBert_ENG\"\n",
        "bert_model_name = \"medicalai/ClinicalBERT\"\n",
        "num_labels = len(label_dict)\n",
        "max_length = max_len * 2\n",
        "\n",
        "# model = UMLSBertCNN(bert_model_name, num_labels)\n",
        "# tokenizer = AutoTokenizer.from_pretrained(bert_model_name)\n",
        "\n",
        "# Tokenizer\n",
        "tokenizer = AutoTokenizer.from_pretrained(bert_model_name)\n",
        "\n",
        "# Model\n",
        "# model = AutoModelForSequenceClassification.from_pretrained(bert_model_name, num_labels=num_labels)\n",
        "model = AutoModel.from_pretrained(bert_model_name, num_labels=num_labels)\n",
        "model.to(device)\n",
        "\n",
        "# Vocabulary\n",
        "# vocab = tokenizer.get_vocab()\n",
        "\n",
        "# Tokenize\n",
        "# tok = tokenizer.tokenize"
      ],
      "metadata": {
        "id": "5CqLY0AdEU0s",
        "outputId": "798b47b6-a516-4edf-9056-dcd630c2c474",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at GanjinZero/UMLSBert_ENG and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BertForSequenceClassification(\n",
              "  (bert): BertModel(\n",
              "    (embeddings): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (token_type_embeddings): Embedding(2, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0-11): 12 x BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSdpaSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): BertPooler(\n",
              "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (dropout): Dropout(p=0.1, inplace=False)\n",
              "  (classifier): Linear(in_features=768, out_features=14, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create Dataset and DataLoader\n",
        "train_dataset = EMRDiagcdDataset3(X_train, y_train_dense, tokenizer, max_length)\n",
        "train_loader = DataLoader(train_dataset, batch_size=2)\n",
        "\n",
        "test_dataset = EMRDiagcdDataset3(X_test, y_test_dense, tokenizer, max_length)\n",
        "test_loader = DataLoader(test_dataset, batch_size=2)"
      ],
      "metadata": {
        "id": "2_3zmEuEEhxN"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = torch.optim.Adam(model.parameters(), lr=2e-5)\n",
        "num_epochs = 1\n",
        "\n",
        "model.train()\n",
        "train_model(model, train_loader, optimizer, num_epochs)"
      ],
      "metadata": {
        "id": "E0iz4Ee8wHgn",
        "outputId": "4c0281d9-8dac-41eb-e9f6-5a39e183893e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 341
        }
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "stack expects each tensor to be equal size, but got [1, 25] at entry 0 and [1, 71] at entry 1",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-39-bb715657bdf8>\u001b[0m in \u001b[0;36m<cell line: 5>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_epochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-38-eb22b8c4c324>\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(model, train_loader, optimizer, num_epochs)\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_epochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m         \u001b[0mrunning_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m             \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    629\u001b[0m                 \u001b[0;31m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    630\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 631\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    632\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    633\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    673\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    674\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 675\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    676\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    677\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     52\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 54\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollate_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/collate.py\u001b[0m in \u001b[0;36mdefault_collate\u001b[0;34m(batch)\u001b[0m\n\u001b[1;32m    314\u001b[0m         \u001b[0;34m>>\u001b[0m\u001b[0;34m>\u001b[0m \u001b[0mdefault_collate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Handle `CustomType` automatically\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    315\u001b[0m     \"\"\"\n\u001b[0;32m--> 316\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mcollate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcollate_fn_map\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdefault_collate_fn_map\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/collate.py\u001b[0m in \u001b[0;36mcollate\u001b[0;34m(batch, collate_fn_map)\u001b[0m\n\u001b[1;32m    171\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    172\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0melem\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 173\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mcollate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msamples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcollate_fn_map\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcollate_fn_map\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0msamples\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtransposed\u001b[0m\u001b[0;34m]\u001b[0m  \u001b[0;31m# Backwards compatibility.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    174\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/collate.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    171\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    172\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0melem\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 173\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mcollate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msamples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcollate_fn_map\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcollate_fn_map\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0msamples\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtransposed\u001b[0m\u001b[0;34m]\u001b[0m  \u001b[0;31m# Backwards compatibility.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    174\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/collate.py\u001b[0m in \u001b[0;36mcollate\u001b[0;34m(batch, collate_fn_map)\u001b[0m\n\u001b[1;32m    152\u001b[0m                 \u001b[0;31m# Create a clone and update it if the mapping type is mutable.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    153\u001b[0m                 \u001b[0mclone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0melem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 154\u001b[0;31m                 \u001b[0mclone\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mcollate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0md\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcollate_fn_map\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcollate_fn_map\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;32min\u001b[0m \u001b[0melem\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    155\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mclone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    156\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/collate.py\u001b[0m in \u001b[0;36m<dictcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    152\u001b[0m                 \u001b[0;31m# Create a clone and update it if the mapping type is mutable.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    153\u001b[0m                 \u001b[0mclone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0melem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 154\u001b[0;31m                 \u001b[0mclone\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mcollate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0md\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcollate_fn_map\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcollate_fn_map\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;32min\u001b[0m \u001b[0melem\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    155\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mclone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    156\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/collate.py\u001b[0m in \u001b[0;36mcollate\u001b[0;34m(batch, collate_fn_map)\u001b[0m\n\u001b[1;32m    139\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcollate_fn_map\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0melem_type\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcollate_fn_map\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 141\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mcollate_fn_map\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0melem_type\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcollate_fn_map\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcollate_fn_map\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    142\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mcollate_type\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcollate_fn_map\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/collate.py\u001b[0m in \u001b[0;36mcollate_tensor_fn\u001b[0;34m(batch, collate_fn_map)\u001b[0m\n\u001b[1;32m    211\u001b[0m         \u001b[0mstorage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0melem\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_typed_storage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_new_shared\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnumel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0melem\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    212\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0melem\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnew\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstorage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresize_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0melem\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 213\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    214\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: stack expects each tensor to be equal size, but got [1, 25] at entry 0 and [1, 71] at entry 1"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QEhgUs4FAVnH",
        "outputId": "bc7fd039-3fe8-4754-ff34-fdc31cecd539"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "labels : ['N391' 'N184' 'N185' 'N183' 'N029' 'N182' 'N178' 'R798' 'R808' 'R311'\n",
            " 'N059' 'Z524' 'N028' 'R601']\n"
          ]
        }
      ],
      "source": [
        "# label encoding\n",
        "# unique_label = df['ICD10'].unique()\n",
        "# print(\"labels :\", unique_label)\n",
        "\n",
        "# label_encoder = LabelEncoder()\n",
        "# label_encoder.fit(unique_label)\n",
        "\n",
        "# # Training dataset labels\n",
        "# temp_df = Y_train.to_frame()\n",
        "# temp_df['encoded_ICD10'] = label_encoder.transform(temp_df['ICD10'])\n",
        "# Y_train_encoding = pd.Series(temp_df['encoded_ICD10'])\n",
        "\n",
        "# # Test dataset labels\n",
        "# temp_df = Y_test.to_frame()\n",
        "# temp_df['encoded_ICD10'] = label_encoder.transform(temp_df['ICD10'])\n",
        "# Y_test_encoding = pd.Series(temp_df['encoded_ICD10'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "27mLa-c7BUck"
      },
      "outputs": [],
      "source": [
        "max_len = 2048\n",
        "batch_size = 32\n",
        "warmup_ratio = 0.1\n",
        "num_epochs = 1\n",
        "max_grad_norm = 1\n",
        "log_interval = 200\n",
        "learning_rate =  5e-5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N8gO9kI-BUck",
        "outputId": "eb62e3cb-dc1a-4007-fca5-c5890152ace1"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'nlp' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[34], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Training data loader\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m train_dataset \u001b[38;5;241m=\u001b[39m \u001b[43mEMRDiagcdDataset2\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtok\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvocab\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_len\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m      3\u001b[0m train_loader \u001b[38;5;241m=\u001b[39m DataLoader(train_dataset, batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m32\u001b[39m, shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, num_worker\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m)\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m# Test data loader\u001b[39;00m\n",
            "Cell \u001b[1;32mIn[29], line 5\u001b[0m, in \u001b[0;36mEMRDiagcdDataset2.__init__\u001b[1;34m(self, dataset, sent_idx, label_idx, bert_tokenizer, vocab, max_len, pad, pair)\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, dataset, sent_idx, label_idx, bert_tokenizer, vocab, max_len,\n\u001b[0;32m      3\u001b[0m              pad, pair):\n\u001b[1;32m----> 5\u001b[0m     transform \u001b[38;5;241m=\u001b[39m \u001b[43mnlp\u001b[49m\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mBERTSentenceTransform(\n\u001b[0;32m      6\u001b[0m         bert_tokenizer, max_seq_length\u001b[38;5;241m=\u001b[39mmax_len, vocab\u001b[38;5;241m=\u001b[39mvocab, pad\u001b[38;5;241m=\u001b[39mpad, pair\u001b[38;5;241m=\u001b[39mpair)\n\u001b[0;32m      8\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msentences \u001b[38;5;241m=\u001b[39m [transform([i[sent_idx]]) \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m dataset]\n\u001b[0;32m      9\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlabels \u001b[38;5;241m=\u001b[39m [np\u001b[38;5;241m.\u001b[39mint32(i[label_idx]) \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m dataset]\n",
            "\u001b[1;31mNameError\u001b[0m: name 'nlp' is not defined"
          ]
        }
      ],
      "source": [
        "# Training data loader\n",
        "train_dataset = EMRDiagcdDataset2(X_train, 0, 1, tok, vocab, max_len, True, False)\n",
        "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True, num_worker=5)\n",
        "\n",
        "# Test data loader\n",
        "test_dataset = EMRDiagcdDataset2(X_test, 0, 1, tok, vocab, max_len, True, False)\n",
        "test_loader = DataLoader(test_dataset, batch_size=len(test_dataset), shuffle=false, num_worker=5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jHwgAYzlYQ1d"
      },
      "outputs": [],
      "source": [
        "# Training data loader\n",
        "train_df = pd.concat([X_train, Y_train_encoding, Y_train], axis=1)\n",
        "train_dataset = EMRDiagcdDataset2(train_df)\n",
        "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
        "\n",
        "# Test data loader\n",
        "test_df = pd.concat([X_test, Y_test_encoding, Y_test], axis=1)\n",
        "test_dataset = EMRDiagcdDataset2(test_df)\n",
        "test_loader = DataLoader(test_dataset, batch_size=len(test_dataset), shuffle=false)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qt09Opa6nu50"
      },
      "outputs": [],
      "source": [
        "# train_df.to_excel('D:\\\\sample\\\\content\\\\train_df.xlsx')\n",
        "df.to_excel('D:\\\\sample\\\\content\\\\translated_df.xlsx')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K5bI5tbJBUcl"
      },
      "outputs": [],
      "source": [
        "# class UmlsBERTClassifier(nn.Module):\n",
        "#     def __init__(self,\n",
        "#                  bert,\n",
        "#                  hidden_size = 768,\n",
        "#                  num_classes=14,   ##클래스 수 조정##\n",
        "#                  dr_rate=None,\n",
        "#                  params=None):\n",
        "#         super(UmlsBERTClassifier, self).__init__()\n",
        "#         self.bert = bert\n",
        "#         self.dr_rate = dr_rate\n",
        "\n",
        "#         self.classifier = nn.Linear(hidden_size , num_classes)\n",
        "#         if dr_rate:\n",
        "#             self.dropout = nn.Dropout(p=dr_rate)\n",
        "\n",
        "#     def gen_attention_mask(self, token_ids, valid_length):\n",
        "#         attention_mask = torch.zeros_like(token_ids)\n",
        "#         for i, v in enumerate(valid_length):\n",
        "#             attention_mask[i][:v] = 1\n",
        "#         return attention_mask.float()\n",
        "\n",
        "#     def forward(self, token_ids, valid_length, segment_ids):\n",
        "#         attention_mask = self.gen_attention_mask(token_ids, valid_length)\n",
        "\n",
        "#         _, pooler = self.bert(input_ids = token_ids, token_type_ids = segment_ids.long(), attention_mask = attention_mask.float().to(token_ids.device),return_dict=False)\n",
        "#         if self.dr_rate:\n",
        "#             out = self.dropout(pooler)\n",
        "#         return self.classifier(out)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4EP0rBQOBUcl"
      },
      "outputs": [],
      "source": [
        "# #BERT 모델 불러오기\n",
        "# model = UmlsBERTClassifier(model,  dr_rate=0.5).to(device)\n",
        "\n",
        "# #optimizer와 schedule 설정\n",
        "# no_decay = ['bias', 'LayerNorm.weight']\n",
        "# optimizer_grouped_parameters = [\n",
        "#     {'params': [p for n, p in model.named_parameters() if not any(nd in n for nd in no_decay)], 'weight_decay': 0.01},\n",
        "#     {'params': [p for n, p in model.named_parameters() if any(nd in n for nd in no_decay)], 'weight_decay': 0.0}\n",
        "# ]\n",
        "\n",
        "# optimizer = AdamW(optimizer_grouped_parameters, lr=learning_rate)\n",
        "# loss_fn = nn.CrossEntropyLoss() # 다중분류를 위한 대표적인 loss func\n",
        "\n",
        "# t_total = len(train_dataloader) * num_epochs\n",
        "# warmup_step = int(t_total * warmup_ratio)\n",
        "\n",
        "# scheduler = get_cosine_schedule_with_warmup(optimizer, num_warmup_steps=warmup_step, num_training_steps=t_total)\n",
        "\n",
        "# #정확도 측정을 위한 함수 정의\n",
        "# def calc_accuracy(X,Y):\n",
        "#     max_vals, max_indices = torch.max(X, 1)\n",
        "#     train_acc = (max_indices == Y).sum().data.cpu().numpy()/max_indices.size()[0]\n",
        "#     return train_acc\n",
        "\n",
        "# train_dataloader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rBte9blF10bf"
      },
      "outputs": [],
      "source": [
        "# Define optimizer and loss function\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=2e-5)\n",
        "loss_fn = nn.BCELoss()\n",
        "itr = 1\n",
        "p_itr = 2\n",
        "epochs = 1\n",
        "total_loss = 0\n",
        "total_len = 0\n",
        "total_correct = 0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TiX8sQaST6S8",
        "outputId": "ff72b1dc-96b2-4856-d5b3-c20035855399"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\KLab\\AppData\\Local\\Temp\\ipykernel_29896\\3858523646.py:12: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  diagcd = torch.tensor(diagcd).long().to(device)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "encoded_record :  {'input_ids': tensor([[    2, 18846,  1828,  ...,     0,     0,     0],\n",
            "        [    2,  3326,    17,  ...,     0,     0,     0],\n",
            "        [    2, 11016, 10290,  ...,     0,     0,     0],\n",
            "        ...,\n",
            "        [    2,  2784, 10281,  ...,     0,     0,     0],\n",
            "        [    2,  1725,  3517,  ...,     0,     0,     0],\n",
            "        [    2, 21047,    15,  ...,     0,     0,     0]], device='cuda:0'), 'token_type_ids': tensor([[0, 0, 0,  ..., 0, 0, 0],\n",
            "        [0, 0, 0,  ..., 0, 0, 0],\n",
            "        [0, 0, 0,  ..., 0, 0, 0],\n",
            "        ...,\n",
            "        [0, 0, 0,  ..., 0, 0, 0],\n",
            "        [0, 0, 0,  ..., 0, 0, 0],\n",
            "        [0, 0, 0,  ..., 0, 0, 0]], device='cuda:0'), 'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
            "        [1, 1, 1,  ..., 0, 0, 0],\n",
            "        [1, 1, 1,  ..., 0, 0, 0],\n",
            "        ...,\n",
            "        [1, 1, 1,  ..., 0, 0, 0],\n",
            "        [1, 1, 1,  ..., 0, 0, 0],\n",
            "        [1, 1, 1,  ..., 0, 0, 0]], device='cuda:0')}\n",
            "diagcd :  tensor([ 5,  9,  7,  4,  6,  5,  7,  5,  9,  5,  3,  8,  1, 12,  5,  5, 13,  1,\n",
            "         7,  7,  5,  6,  7,  5,  5,  4,  7,  5,  5,  6,  5,  2],\n",
            "       device='cuda:0')\n",
            "logits :  tensor([[ 1.0763,  0.8755,  0.7501,  3.9914,  0.3897,  5.5685, -0.0482,  0.6455,\n",
            "          7.3030,  2.6921, -0.7495,  1.4843,  1.2332, -0.3037],\n",
            "        [ 0.3305,  1.3046,  1.2720,  1.8497, -0.7849,  4.9292, -0.2217,  0.2859,\n",
            "          5.0947,  2.5298, -2.3454,  1.1797,  0.2908, -0.5654],\n",
            "        [ 1.8534,  1.5687,  0.5931,  2.6218, -0.5516,  4.2859, -0.7795,  0.1677,\n",
            "          5.9723,  1.9594, -2.3371,  1.6503,  1.7737, -0.4444],\n",
            "        [ 1.3053,  1.4795,  0.5252,  2.9548, -1.0840,  5.2195, -0.0658, -0.2617,\n",
            "          5.8493,  2.1521, -1.9406,  1.5399,  1.6895, -0.2114],\n",
            "        [ 1.2989,  0.9894,  0.2832,  2.5469, -1.7598,  4.5556, -1.6128, -0.3022,\n",
            "          5.6881,  2.1608, -1.8196,  1.6118,  2.5161, -0.5033],\n",
            "        [ 1.3492,  1.1309,  0.1754,  2.6044, -0.4201,  4.7566, -0.0980,  0.0567,\n",
            "          6.1870,  2.3882, -1.8336,  2.0366,  1.7555,  0.8102],\n",
            "        [ 1.4840,  1.8314,  0.9473,  3.3890, -1.6078,  4.2496, -1.2636,  0.1233,\n",
            "          5.6930,  2.1447, -1.9735,  2.2061,  1.9612,  0.6515],\n",
            "        [ 1.5319,  1.0852,  1.1305,  3.2417,  0.9064,  5.2253, -1.0055,  0.7339,\n",
            "          5.9110,  2.1391, -1.8747,  2.1212,  1.5477, -0.4185],\n",
            "        [ 1.5848,  1.0662,  0.9496,  3.5917,  0.6668,  5.2202, -0.5523,  0.6947,\n",
            "          6.4940,  2.6970, -2.0600,  1.7015,  1.5068,  0.0525],\n",
            "        [ 1.9787,  0.7972,  1.3140,  3.2860,  0.1881,  5.6015,  0.4076, -0.1963,\n",
            "          6.6012,  2.5488, -1.5155,  1.4423,  0.3126, -0.3799],\n",
            "        [ 1.9900,  0.9197,  0.3215,  3.4798, -0.6999,  4.8781, -0.1181, -0.0730,\n",
            "          6.1838,  1.9077, -0.9164,  1.4801,  1.3159,  0.1854],\n",
            "        [ 1.2481,  1.3201,  0.7464,  3.0657, -1.9768,  5.1773,  0.0147,  0.0196,\n",
            "          6.1420,  1.9002, -1.8976,  1.4138,  1.6154,  0.8333],\n",
            "        [ 0.6205,  1.3943,  1.0463,  2.7532, -1.0311,  5.3726,  0.2427,  0.0208,\n",
            "          5.6010,  2.4435, -2.1659,  1.0565,  1.5139, -0.2796],\n",
            "        [ 1.8030,  0.8380,  1.6902,  2.8382,  0.0833,  5.7628, -0.1184,  0.0195,\n",
            "          6.4469,  1.7057, -0.7014,  1.3534,  1.8513, -0.3814],\n",
            "        [ 2.1026,  1.3476,  0.4741,  2.4064, -1.3293,  5.1932,  0.0835,  0.2576,\n",
            "          6.3734,  2.1278, -1.4141,  2.1068,  1.9173,  0.0715],\n",
            "        [ 2.6733,  1.6027,  0.3380,  2.9412, -2.0906,  4.3585, -0.8654, -0.2521,\n",
            "          5.5895,  1.9374, -1.3436,  2.2728,  2.2780, -0.5076],\n",
            "        [ 0.7503,  0.8618,  1.2261,  3.1433, -0.7249,  5.1271,  0.3968,  0.4443,\n",
            "          6.5387,  1.8804, -1.5806,  0.6829,  0.3446, -0.0795],\n",
            "        [ 2.0688,  1.0394,  1.2211,  3.2852,  0.1170,  5.3075,  0.3063,  1.4400,\n",
            "          6.3077,  2.3786, -2.2669,  1.2867,  1.6184,  0.6759],\n",
            "        [ 1.1120,  0.7598,  0.7705,  2.7417, -0.2301,  5.0115,  0.4158,  0.7319,\n",
            "          5.8112,  1.6342, -1.7081,  1.2788,  0.9116, -0.0863],\n",
            "        [ 1.3483,  0.8078,  0.4675,  3.2423,  0.6178,  4.9633,  0.1251,  0.4026,\n",
            "          5.8307,  2.6304, -1.9417,  1.8127,  1.3789, -0.2493],\n",
            "        [ 1.4393,  1.4457,  1.0176,  2.9342,  0.2176,  5.4492, -0.7319,  1.1878,\n",
            "          5.6865,  1.9581, -1.4035,  1.3678,  1.2286, -0.4499],\n",
            "        [ 1.1897,  0.3865,  1.2377,  2.9820, -1.5360,  5.1132,  0.0210,  0.1447,\n",
            "          5.4371,  1.8711, -1.5013,  1.5266,  1.4121, -0.4049],\n",
            "        [ 1.7918,  0.8245,  0.6566,  3.1294, -1.1886,  4.8320, -0.0784,  0.2917,\n",
            "          6.1037,  1.8924, -1.6677,  2.2970,  2.1153,  0.7773],\n",
            "        [ 1.9549,  1.7321,  0.2369,  3.3789, -1.2683,  4.2370,  0.4755,  0.0308,\n",
            "          5.9746,  2.2781, -1.2334,  2.0535,  1.8432,  0.4392],\n",
            "        [ 0.9354,  1.0136,  0.6781,  2.5900, -1.8259,  4.8355,  0.2733, -0.0590,\n",
            "          5.9091,  2.4243, -2.5419,  2.0613,  1.3960,  0.1372],\n",
            "        [ 1.6404,  1.2463,  0.3888,  2.7601, -0.1278,  5.2424, -0.0474,  0.6584,\n",
            "          5.3012,  2.1669, -1.8864,  1.5038,  1.8181, -0.3886],\n",
            "        [ 1.8942,  1.1052,  0.4922,  2.9959, -0.3042,  5.1169, -0.1603,  0.2001,\n",
            "          5.0563,  1.7904, -1.5750,  1.1017,  1.4015,  0.1152],\n",
            "        [ 2.0377,  1.3361,  0.9817,  2.7479,  0.2611,  4.7454, -0.3537,  0.2091,\n",
            "          5.5187,  2.1021, -2.3444,  1.7853,  1.9463,  0.1068],\n",
            "        [ 1.4907,  2.1018,  1.0698,  3.1642,  0.2914,  5.0345, -0.5476,  0.2569,\n",
            "          6.1559,  1.5501, -1.1332,  1.2577,  0.5236,  0.1433],\n",
            "        [ 1.7901,  0.8065,  0.7447,  3.3212, -1.0839,  4.8841, -0.0939,  0.2048,\n",
            "          6.0064,  2.3026, -0.9594,  1.3677,  1.6267, -0.4479],\n",
            "        [ 1.2870,  1.2492,  0.0988,  3.1084, -0.5076,  4.7836,  0.2819,  0.1907,\n",
            "          5.5954,  2.1497, -1.6862,  1.0733,  1.9004, -0.2367],\n",
            "        [ 0.6215,  0.7205,  1.1154,  2.8563, -0.6030,  4.9505,  0.1846, -0.4334,\n",
            "          4.4346,  1.4906, -1.9277,  1.8875,  1.7951, -0.2381]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "predict :  tensor([15,  6, 31,  6,  7, 31, 31, 20,  0,  1, 29, 31,  4,  6],\n",
            "       device='cuda:0')\n",
            "predict sum:  tensor(218, device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\KLab\\AppData\\Local\\Temp\\ipykernel_29896\\3858523646.py:26: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  predict = torch.argmax(F.softmax(logits), dim=0)\n"
          ]
        },
        {
          "ename": "RuntimeError",
          "evalue": "The size of tensor a (14) must match the size of tensor b (32) at non-singleton dimension 0",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[128], line 29\u001b[0m\n\u001b[0;32m     27\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpredict : \u001b[39m\u001b[38;5;124m'\u001b[39m, predict)\n\u001b[0;32m     28\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpredict sum: \u001b[39m\u001b[38;5;124m'\u001b[39m, predict\u001b[38;5;241m.\u001b[39msum())\n\u001b[1;32m---> 29\u001b[0m correct \u001b[38;5;241m=\u001b[39m \u001b[43mpredict\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meq\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdiagcd\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     30\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcorrect : \u001b[39m\u001b[38;5;124m'\u001b[39m, correct)\n\u001b[0;32m     31\u001b[0m total_correct \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m correct\u001b[38;5;241m.\u001b[39msum()\u001b[38;5;241m.\u001b[39mitem()\n",
            "\u001b[1;31mRuntimeError\u001b[0m: The size of tensor a (14) must match the size of tensor b (32) at non-singleton dimension 0"
          ]
        }
      ],
      "source": [
        "# train\n",
        "model.train()\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    for record, diagcd in train_loader:\n",
        "        optimizer.zero_grad()\n",
        "        # print(\"record: \", record)\n",
        "        # print(\"diagcd: \", diagcd)\n",
        "        encoded_record = tokenizer(record, padding=True, truncation=True, max_length=512, return_tensors=\"pt\")\n",
        "        encoded_record = encoded_record.to(device)\n",
        "        # print(type(encoded_record))\n",
        "        diagcd = torch.tensor(diagcd).long().to(device)\n",
        "        # diagcd = torch.tensor(list(diagcd), dim=0).to(device)\n",
        "\n",
        "        outputs = model(**encoded_record, labels=diagcd)\n",
        "\n",
        "        loss = outputs.loss\n",
        "        logits = outputs.logits\n",
        "\n",
        "        # print('lsos : ', loss)\n",
        "        # print('record : ', record)\n",
        "        print('encoded_record : ', encoded_record)\n",
        "        print('diagcd : ', diagcd)\n",
        "        print('logits : ', logits)\n",
        "\n",
        "        predict = torch.argmax(F.softmax(logits), dim=0)\n",
        "        print('predict : ', predict)\n",
        "        print('predict sum: ', predict.sum())\n",
        "        correct = predict.eq(diagcd)\n",
        "        print('correct : ', correct)\n",
        "        total_correct += correct.sum().item()\n",
        "        total_len += len(diagcd)\n",
        "        total_loss += loss.item()\n",
        "\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        if itr % p_itr == 0:\n",
        "            print('[Epoch {}/{}] Iteration {} -> Train Loss: {:.4f}, Accuracy: {:.3f}'.format(epoch+1, epochs, itr, total_loss/p_itr, total_correct/total_len))\n",
        "            total_loss = 0\n",
        "            total_len = 0\n",
        "            total_correct = 0\n",
        "\n",
        "        itr += 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rNjToVkPYNAQ",
        "outputId": "230314fc-8ef4-4026-f84c-545072b5ae9c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                                              transstr  encoded_ICD10 ICD10\n",
            "278  114-69-88 2 years ago Urology and Browno Holy ...              9  R311\n",
            "690  97-53-112 Diabetes and Hypertension-more than ...              5  N183\n",
            "108  145-75-85 2023.4.Microscopic Hematuria 2022.10...              9  R311\n",
            "499  2023/04 I heard that there is proteinuria duri...              9  R311\n",
            "755  The patient is a patient of 77 years old, curr...              5  N183\n",
            "..                                                 ...            ...   ...\n",
            "228  The patient is a diagnostic name [Paralysis of...              5  N183\n",
            "151  # HTN (2022.)2023. CR 1.24 EGFR 41 EGFR K 5.7 ...              5  N183\n",
            "129  The patient is a diagnostic [DJD] patient of 8...              5  N183\n",
            "781  We will ask for consultation.The patient is a ...              9  R311\n",
            "159  20 years ago, DM, HTN diagnosis 10 years ago, ...              5  N183\n",
            "\n",
            "[83 rows x 3 columns]\n"
          ]
        }
      ],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nOFsEw-xXmg5",
        "outputId": "c8c9a935-7d89-4ccb-c775-310acad19f74"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\KLab\\AppData\\Local\\Temp\\ipykernel_88648\\1370849160.py:16: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  predict = torch.argmax(F.softmax(logits), dim=1)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test accuracy:  0.0963855421686747\n"
          ]
        }
      ],
      "source": [
        "# evaluation\n",
        "model.eval()\n",
        "\n",
        "total_len = 0\n",
        "total_correct = 0\n",
        "\n",
        "for record, diagcd in test_loader:\n",
        "\n",
        "    encoded_record = tokenizer(record, padding=True, truncation=True, max_length=512, return_tensors=\"pt\")\n",
        "    encoded_record, diagcd = encoded_record.to(device), diagcd.long().to(device)\n",
        "\n",
        "    outputs = model(**encoded_record, labels=diagcd)\n",
        "\n",
        "    logits = outputs.logits\n",
        "\n",
        "    predict = torch.argmax(F.softmax(logits), dim=1)\n",
        "    correct = predict.eq(diagcd)\n",
        "\n",
        "    total_correct += correct.sum().item()\n",
        "    total_len += len(diagcd)\n",
        "\n",
        "print('Test accuracy: ', total_correct / total_len)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "L4",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}